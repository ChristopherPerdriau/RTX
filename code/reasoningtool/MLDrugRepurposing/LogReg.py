import pandas as pd
import numpy as np
import scipy as sci
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import sklearn as skl
import sklearn.linear_model as lm
import sklearn.externals as ex
import sklearn.metrics as met
import sklearn.model_selection as ms
import time
import argparse
import ast
from sklearn.externals import joblib

parser = argparse.ArgumentParser()
parser.add_argument("--tp", type=str, nargs='*', help="The filenames or paths to the true positive csvs", default=['semmed_tp.csv','mychem_tp.csv','mychem_tp_umls.csv','NDF_TP.csv'])
parser.add_argument("--tn", type=str, nargs='*', help="The filenames or paths to the true negative csvs", default=['semmed_tn.csv','mychem_tn.csv','mychem_tn_umls.csv','NDF_TN.csv'])
parser.add_argument("--emb", type=str, help="The filename or path of the emb file generated for your graph", default="graph.emb")
parser.add_argument("--map", type=str, help="The filename or path of the map file generated by EdgelistMaker.py", default="map.csv")
parser.add_argument("-c", "--cutoff", type=int, help="A positive integer for the cutoff of SemMedDB hot counts to include in analysis", default=2)
parser.add_argument("--roc", type=bool, help="A boolian indicating weather or not to print a roc curve for the model", default=False)

args = parser.parse_args()

class LogReg():
    """
    This class takes the output of node2vec and trains a logistic regression model using true positive and true negative data

    :param node_vec_file: A string containing the file name of the .emb output file generated by node2vec.
    :param map_file: A string containing the file name of the map file that converts between curie ids and the corresponding integers used for node2vec
    :param TP_name_list: A list of strings containing the csvs with the True Positives in it.
    :param TN_name_list: A list of strings containing the csvs with the True Negatives in it.
    :param cutoff: A positive integer indicating the cutoff of SemMedDB hit counts to include (2 means 2 or more hits included)
    """

    def __init__(self, node_vec_file = 'q_1_p_1_e_5_d_128_l_100_r_15_directed.emb', map_file = 'map.csv', TP_name_list = ['c_tp2.csv','NDF_TP2.csv'], TN_name_list = ['c_tn2.csv','NDF_TN2.csv'], cutoff = 2):

        # Loads the generated emb file and the curie -> integer id map file
        self.node_vec = pd.read_csv(node_vec_file, sep = ' ', skiprows=1, header = None, index_col=None)
        map_df = pd.read_csv(map_file, index_col=None)

        # Sorts the rows of the vectorized nodes by integer id for quick retrieval
        self.node_vec = self.node_vec.sort_values(0).reset_index(drop=True)

        map_dict = {}
        drug_ids = []
        dis_ids = []

        # Build dict mapping curie -> id
        for row in range(len(map_df)):
            map_dict[map_df['curie'][row]] = map_df['id'][row]

        TP_list = []
        TN_list = []

        # generate list of true positive and true negative data frames
        for i in range(len(TP_name_list)):
            TP_list += [pd.read_csv(TP_name_list[i],index_col=None)]

        for i in range(len(TN_name_list)):
            TN_list += [pd.read_csv(TN_name_list[i],index_col=None)]

        y = []
        X = []

        y1 = []
        X1 = []

        y2 = []
        X2 = []

        c = 0

        id_list = []
        id_list_dict = dict()

        # Generate true negative training set by concatinating source-target pair vectors
        for TN in TN_list:
            for row in range(len(TN)):
                if 'count' in list(TN):
                    if int(TN['count'][row]) < cutoff:
                        continue
                try:
                    source_id = map_dict[TN['source'][row]]
                    source_curie = TN['source'][row]
                    target_id = map_dict[TN['target'][row]]
                    target_curie = TN['target'][row]
                except KeyError:
                    c += 1
                    continue

                if (source_curie, target_curie) not in id_list_dict:
                    id_list += [[source_curie, target_curie]]
                    id_list_dict[source_curie, target_curie] = 0
                    X2 += [list(self.node_vec.iloc[source_id,1:]) + list(self.node_vec.iloc[target_id,1:])]

        # Generate true positive training set by concatinating source-target pair vectors
        for TP in TP_list:
            for row in range(len(TP)):
                if 'count' in list(TP):
                    if int(TP['count'][row]) < cutoff + 10:
                        continue
                try:
                    source_id = map_dict[TP['source'][row]]
                    source_curie = TP['source'][row]
                    target_id = map_dict[TP['target'][row]]
                    target_curie = TP['target'][row]
                except KeyError:
                    c += 1
                    continue

                if (source_curie, target_curie) not in id_list_dict:
                    id_list += [[source_curie, target_curie]]
                    id_list_dict[source_curie, target_curie] = 1
                    X1 += [list(self.node_vec.iloc[source_id,1:]) + list(self.node_vec.iloc[target_id,1:])]

        # Assign 0 to negatives and 1 to positives
        y1 = [1]*len(X1)
        y2 = [0]*len(X2)

        # Convert to numpy arrays and concatinate
        X1 = np.array(X1)
        y1 = np.array(y1)
        X2 = np.array(X2)
        y2 = np.array(y2)
        X = np.concatenate((X1,X2))
        y = np.concatenate((y1,y2))

        # Assign to class attribute
        self.X = X
        self.y = y
        self.id_list = id_list


    def max_lr_f1(self, C_flag = False, save = False):
        """
        This uses LogisticRegressionCV to find the maximum mean f1 score using by adjusting the C parameter

        :param C_flag: A boolian indicating what to output from the function. (if False output the max mean f1, if True output the C value used to find the maximum mean f1 score)
        """

        # seeds random state from time
        random_state = np.random.RandomState(int(time.time()))
        np.random.seed(int(time.time()/100))

        # Uncomment if you want to seed random state from iteger instead (to be able to repeat exact results)
        #random_state = np.random.RandomState(11235813)
        #np.random.seed(112358)

        # Sets up 10-fold cross validation set
        cv = ms.StratifiedKFold(n_splits=10, random_state=random_state, shuffle=True)
        
        # Sets and fits Logistic Regression Model
        model2 = lm.LogisticRegressionCV(class_weight='balanced', random_state = random_state, cv = cv, n_jobs=-1, scoring = 'f1')
        model2.fit(self.X, self.y)
        
        # saves the model
        if save:
            joblib.dump(model2, 'data/LogRegModel.pkl')
        
        # returns the c value or f1 score
        if C_flag:
            return model2.C_[0]
        else:
            return model2.scores_[1].mean(axis=0).max()

    def lr_roc_curve(self,C):
        """
        This generates a roc curve using logistic regression and 10 fold crossvalidation

        :param C: The C parameter used for the logistic regression.
        """
        # sets model
        model = lm.LogisticRegression(class_weight='balanced', C = C)

        # seeds random state from time
        random_state = np.random.RandomState(int(time.time()))
        np.random.seed(int(time.time()/100))

        # Uncomment if you want to seed random state from iteger instead (to be able to repeat exact results)
        #random_state = np.random.RandomState(11235813)
        #np.random.seed(112358)

        # Sets up 10-fold cross validation set
        cv = ms.StratifiedKFold(n_splits=10, random_state=random_state, shuffle=True)

        tprs = []
        aucs = []
        f1s = []
        mean_fpr = np.linspace(0, 1, 100)

        i = 0

        # Creates a shuffled index for X and y
        shuffled_idx = np.arange(len(self.y))
        np.random.shuffle(shuffled_idx)

        # Uncomment if you want it to find and print the mean f1 score
        #test_f1_mean = np.mean(ms.cross_val_score(model, self.X[shuffled_idx], self.y[shuffled_idx], cv=10, n_jobs=-1, scoring='f1'))
        #print('using cross val score F1 = %0.4f' % (test_f1_mean))

        # Calculates and plots the roc cureve for each set in 10-fold cross validation
        for train, test in cv.split(self.X, self.y):
            model_i = model.fit(self.X[train], self.y[train])
            probas_ = model_i.predict_proba(self.X[test])
            pred = model_i.predict(self.X[test])
            f1 = met.f1_score(self.y[test], pred, average='binary')
            f1s.append(f1)
            # Compute ROC curve and area the curve
            fpr, tpr, thresholds = met.roc_curve(self.y[test], probas_[:, 1])
            tprs.append(sci.interp(mean_fpr, fpr, tpr))
            tprs[-1][0] = 0.0
            roc_auc = met.auc(fpr, tpr)
            aucs.append(roc_auc)
            plt.plot(fpr, tpr, lw=1, alpha=0.3,
                    label='ROC fold %d (AUC = %0.4f, F1 = %0.4f)' % (i, roc_auc, f1))

            i += 1

        # Plots the 50/50 line
        plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',
                label='Coin Flip', alpha=.8)

        # Finds and plots the mean roc curve and mean f1 score
        mean_tpr = np.mean(tprs, axis=0)
        mean_f1 = np.mean(f1s)
        mean_tpr[-1] = 1.0
        mean_auc = met.auc(mean_fpr, mean_tpr)
        std_auc = np.std(aucs)
        plt.plot(mean_fpr, mean_tpr, color='b',
                label=u'Mean ROC (AUC = %0.4f \u00B1 %0.4f, \n        \
                    Mean F1 = %0.4f)' % (mean_auc, std_auc, mean_f1),
                lw=2, alpha=.8)

        # Finds and plots the +- standard deviation for roc curve
        std_tpr = np.std(tprs, axis=0)
        tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
        tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
        plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,
                        label=r'$\pm$ 1 std. dev.')

        # Sets legend, limits, labels, and displays plot
        plt.xlim([-0.05, 1.05])
        plt.ylim([-0.05, 1.05])
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title('Receiver Operating Characteristic')
        plt.legend(loc="lower right")
        plt.show()


    def test_f1(self):
        print(self.max_lr_f1())

    def test_roc(self):
        self.lr_roc_curve(self.max_lr_f1(True))

if __name__ == "__main__":
    lr = LogReg(node_vec_file = args.emb, map_file = args.map, TP_name_list = args.tp, TN_name_list = args.tn, cutoff = args.cutoff)
    c = lr.max_lr_f1(C_flag = True,save=True)
    if(args.roc):
        lr.lr_roc_curve(c)



